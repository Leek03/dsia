{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOGGU7gNKck0"
   },
   "source": [
    " ![alt text](https://i.imgur.com/1WaY7aA.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_D_idRWZKck4"
   },
   "source": [
    "# Lab 2.2.3 \n",
    "# *Mining Social Media on Reddit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atJ1XMr3Kck7"
   },
   "source": [
    "## The Reddit API and the PRAW Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJ9o1EfAKck-"
   },
   "source": [
    "The Reddit API is rich and complex, with many endpoints (https://www.reddit.com/dev/api/). It includes methods for navigating its collections, which include various kinds of media as well as comments. Fortunately, the Python library PRAW reduces much of this complexity.\n",
    "\n",
    "Reddit requires developers to create and authenticate an app before they can use the API, but the process is much less onerus than some, and does not have waiting period for approval of new developers (as of 18 August 2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egz9IUhlKclB"
   },
   "source": [
    "### 1. Create a Reddit App\n",
    "\n",
    "Go to https://www.reddit.com/prefs/apps and click \"create an app\".\n",
    "\n",
    "Enter the following in the form:\n",
    "\n",
    "- a name for your app\n",
    "- select \"script\" radio button\n",
    "- a description\n",
    "- a redirect URI\n",
    "\n",
    "(Nb. For pulling data into a data science experiment, a local port can be used for the Redirect URI; try http://127.0.0.1:1410)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "- click \"create app\"\n",
    "- from the form that displays, copy the following to a local text file (or to this notebook):\n",
    "\n",
    "  - name (the name you gave to your app)\n",
    "  - redirect URI\n",
    "  - personal use script (this is your OAuth 2 Client ID)\n",
    "  - secret (this is your OAuth 2 Secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LF9V-LJ2KclE"
   },
   "source": [
    "### 2. Register for API Access\n",
    "\n",
    "- follow the link at https://www.reddit.com/wiki/api and read the terms of use for Reddit API access \n",
    "- fill in the form fields at the bottom \n",
    "  - make sure to enter your new OAuth Client ID where indicated\n",
    "  - your use case could be something like \"Training in API usage for data science projects\"\n",
    "  - your platform could be something like \"Jupyter Notebooks / Python\"\n",
    "  \n",
    "- click \"SUBMIT\"\n",
    " \n",
    "- when asked for User-Agent, enter something that fits this pattern:\n",
    "  `your_os-python:your_reddit_appname:v1.0 (by /u/your_reddit_username)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIsv8YAMKclG"
   },
   "source": [
    "### 3. Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqi2BT66KclI"
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "from datetime import datetime, date, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwXaO9GPKclP"
   },
   "source": [
    "### 4. Authenticate from your Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF5oh54RKclR"
   },
   "source": [
    "You could assign your authentication details explicitly, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH2-X9juKclS"
   },
   "outputs": [],
   "source": [
    "my_user_agent = ''   # your user Agent string goes in here\n",
    "my_client_id = ''   # your Client ID string goes in here\n",
    "my_client_secret = ''   # your Secret string goes in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auth_reddit = {}  \n",
    "auth_reddit['credentials'] = []  \n",
    "auth_reddit['credentials'].append({  \n",
    "    'my_client_id': 'UqC3l_vLO1Q7PA',\n",
    "    'my_user_agent': 'UqC3l_vLO1Q7PA',\n",
    "    'my_client_secret': '-nNZEiUQEsJ-ON0Y-HJxyn90N2M'\n",
    "})\n",
    "\n",
    "with open('auth_reddit.txt', 'w') as outfile:  \n",
    "    json.dump(auth_reddit, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TmzPxHIKclX"
   },
   "source": [
    "A better way would be to store these details externally, so they are not displayed in the notebook:\n",
    "\n",
    "- create a file called \"auth_reddit.json\" in your \"notebooks\" directory, and save your credentials there in JSON format:\n",
    "\n",
    "`{   \"my_client_id\": \"your Client ID string goes in here\",` <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;` \"my_client_secret\": \"your Secret string goes in here\",` <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`\"my_user_agent\": \"your user Agent string goes in here\"` <br>\n",
    "`}`\n",
    "\n",
    "Use the following code to load the credentials:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFbFWGnVKclY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Vani/Documents/BlackCat/DSIA-SYD-FT-Projects-201907/Vani/LABS 2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()  # make sure your working directory is where the file is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auth_reddit.txt') as json_file:  \n",
    "    auth_reddit = json.load(json_file)\n",
    "\n",
    "# For debugging only:\n",
    "#pp.pprint(auth)\n",
    "for p in auth_reddit['credentials']:\n",
    "    my_client_id = p['my_client_id']\n",
    "    my_user_agent = p['my_user_agent']\n",
    "    my_client_secret = p['my_client_secret']\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVKFy9rZKclf"
   },
   "source": [
    "Security considerations: \n",
    "- this method only keeps your credentials invisible as long as nobody else gets access to this notebook file \n",
    "- if you wanted another user to have access to the executable notebook without divulging your credentials you should set up an OAuth 2.0 workflow to let them obtain and apply their own API tokens when using your app\n",
    "- if you just want to share your analyses, you could use a separate script (which you don't share) to fetch the data and save it locally, then use a second notebook (with no API access) to load and analyse the locally stored data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgHqt72rKclg"
   },
   "source": [
    "### 5. Exploring the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByEQS6QsKclh"
   },
   "source": [
    "Here is how to connect to Reddit with read-only access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hkZJlcJKcli"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read-only = True\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id = my_client_id, \n",
    "                     client_secret = my_client_secret, \n",
    "                     user_agent = my_user_agent)\n",
    "\n",
    "print('Read-only = ' + str(reddit.read_only))  # Output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slGz0lS5Kclk"
   },
   "source": [
    "In the next cell, put the cursor after the '.' and hit the [tab] key to see the available members and methods in the response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MvyYewEKcll"
   },
   "outputs": [],
   "source": [
    "reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKfXBu7yKcln"
   },
   "source": [
    "Consult the PRAW and Reddit API documentation. Print a few of the response members below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31Njl99lKcln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5L10cuKfKclp"
   },
   "source": [
    "Content in Reddit is grouped by topics called \"subreddits\". Content, called \"submissions\", is fetched by calling the `subreddit` method of the connection object (which is our `reddit` variable) with an argument that matches an actual topic. \n",
    "\n",
    "We also need to append a further method call to a \"subinstance\", such as one of the following:\n",
    "\n",
    "- controversial\n",
    "- gilded\n",
    "- hot\n",
    "- new\n",
    "- rising\n",
    "- top\n",
    "\n",
    "One of the submission objects members is `title`. Fetch and print 10 submission titles from the 'learnpython' subreddit using one of the subinstances above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2W1iCDE9Kclp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything Monday - Weekly Thread\n",
      "How can I best determine which variable is causing memory bloat?\n",
      "Quick question about python behavior. 3.7.4\n",
      "Why this code works without the \"import\", and also what this means\n",
      "Could someone give me some great source for learning that are free (beginners)?\n",
      "Best way to learn python need recommendation\n",
      "How do you manage the time-based flow of code?\n",
      "Trying to get better with for loops\n",
      "First 'largish' project - Classic Games Command Line System\n",
      "MRI Image Segmentation\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit('learnpython').hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00coF0YJKclr"
   },
   "source": [
    "Now retrieve 10 authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1vTByCGKclr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoModerator\n",
      "grumpyThrifter\n",
      "Crevette3\n",
      "Joluall\n",
      "hellotheresksksk\n",
      "Ghost_Dak1\n",
      "hungarywolf\n",
      "notsociallyakward\n",
      "TheDwarfBard\n",
      "nierp\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit('learnpython').hot(limit=10):\n",
    "    print(submission.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOFMMl6AKclt"
   },
   "source": [
    "Note that we obtained the titles and authors from separate API calls. Can we expect these to correspond to the same submissions? If not, how could we gurantee that they do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIPVr-WaKclu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: AutoModerator | Title: Ask Anything Monday - Weekly Thread\n",
      "Author: grumpyThrifter | Title: How can I best determine which variable is causing memory bloat?\n",
      "Author: Crevette3 | Title: Quick question about python behavior. 3.7.4\n",
      "Author: Joluall | Title: Why this code works without the \"import\", and also what this means\n",
      "Author: hellotheresksksk | Title: Could someone give me some great source for learning that are free (beginners)?\n",
      "Author: Ghost_Dak1 | Title: Best way to learn python need recommendation\n",
      "Author: hungarywolf | Title: How do you manage the time-based flow of code?\n",
      "Author: notsociallyakward | Title: Trying to get better with for loops\n",
      "Author: TheDwarfBard | Title: First 'largish' project - Classic Games Command Line System\n",
      "Author: nierp | Title: MRI Image Segmentation\n"
     ]
    }
   ],
   "source": [
    "submissions = reddit.subreddit('learnpython').hot(limit=10)\n",
    "for submission in submissions:\n",
    "    print(\"Author: {} | Title: {}\".format(submission.author, submission.title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjIJ6ojAKclv"
   },
   "source": [
    "Why doesn't the next cell produce output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifxjcJ2aKclw"
   },
   "outputs": [],
   "source": [
    "for submission in submissions:\n",
    "    print(submission.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPNVNapBKcly"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "praw.models.listing.generator.ListingGenerator"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4aZ2OSd_Kclz"
   },
   "source": [
    "Print two comments associated with each of these submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RO4ppDPJKcl0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any recommended projects to contribute to for someone who has somewhat of background in data structures/algs but has never contributed to anything before?\n",
      "At this point I'm entirely self taught. Only started recently but I am happy enough with my progress. I'll be starting college in September, first time learning code in a classroom setting. Anybody have any study tips? My undergraduate degree was in business so I imagine studying best practices are different in such different fields.\n",
      "> The only thing I can think of that might be causing the bloat is that it creates a lot of threads that perform http requests which it does not explicitly close... but I thought they were garbage collected automatically when they're done executing?\n",
      "\n",
      "Only if you relinquish all of the references. Are you? If you're spawning threads and then keeping some kind of list of them, they won't be garbage collected even when they've died. You need to actually delete the reference so they can be subject to GC - Python's GC is based on reference counting.\n",
      "[https://pypi.org/project/memory-profiler/](https://pypi.org/project/memory-profiler/) might be a place to start\n",
      "What you probably want is\n",
      "\n",
      "    inventory[item] += 1\n",
      "\n",
      "while this line:\n",
      "\n",
      "    inventory = inventory[item] + 1  \n",
      "\n",
      "would overwrite your entire inventory dict.\n",
      "the `re.compile` line isn't ran until whatever trigger the `.register` is activated \n",
      "\n",
      "python isn't a language that validates everything at compile time, it's an interpreted language and a run time error will happen if you remove `import re`\n",
      "Wait... What you want is to validate if the string can be converted to a float ?\n",
      "\n",
      "try:\n",
      "\n",
      "    value = float(value)\n",
      "\n",
      "except ValueError:\n",
      "\n",
      "    print(\"Invalid value '%s'\" % value)\n",
      "Automate the boring stuff is free on their website but if you want to watch video tutorials it is like 11.99 on udemy.\n",
      "\n",
      "Usually every month udemy has specials where they cut there original price by 80 percent off so you have better chance of buying it.\n",
      "I found this video from Mike Dane to be really well done - Learn Python in 4 hours - https://www.youtube.com/watch?v=rfscVS0vtbw\n",
      "\n",
      "Corey Schafer's Python tutorials are also great quality - https://www.youtube.com/playlist?list=PL-osiE80TeTt2d9bfVyTiXJA-UTHn6WwU\n",
      "\n",
      "I haven't personally done Automate the Boring Stuff but I hear it recommended often - https://automatetheboringstuff.com/\n",
      "From my experience of learning python go for: books, udemy courses, some good sites like \"SoloLearn\"\n",
      "\n",
      "Here are 2 udemy courses i know:\n",
      " https://www.udemy.com/complete-python-bootcamp/\n",
      "\n",
      "\n",
      "https://www.udemy.com/automate/\n",
      "\n",
      "\n",
      "\n",
      "Book :there is a free book you can search up on google called \"automate the boring stuff\"\n",
      "great book is python crash course by matthes (get new 2nd edition)\n",
      "You’re going to have to explain yourself better. I’ve read those first three paragraphs over and over and frankly I don’t really have a picture of what it is your program is trying to do or how you’re currently storing the data. It’s essentially gibberish.\n",
      "\n",
      "Maybe give us some examples of how you’ve been using Datetime currently? How are you gathering the data, how are you storing it, etc.?\n",
      "Not an expert. But you can try to use wait() function to reduce the amount of collected data\n",
      "Don't use for loops with pandas dataframes unless you really, really need to. You can, and it's probably not going to be if most terrible thing for a smaller dataset, but it's not the best way to leverage pandas dataframes. See this SO link for a more thorough explanation (https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas/55557758#55557758)\n",
      "\n",
      "If I am understanding what you do, you want to split your dataframe into 5 year increments, and then show the average funding per town? \n",
      "\n",
      "You can use the pandas groupby functionality (https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html). \n",
      "\n",
      "So a quick example would be something like this:\n",
      "``` g = df[df['date'] < ${five_year_cutoff}].groupby('town_id')```\n",
      "\n",
      "From there you can get the average of each group (in this case based on the 'town_id' attribute:\n",
      "\n",
      "```g.mean()```, or if you wanted the total average of that period, ```df[df['data'] < ${five_year_cutoff}]['funding'].mean()```\n",
      "No loop required. First pivot the table so that you have columns of towns and rows of years (or the other way around). Then use `pandas.rolling_mean` to make a new dataframe with the rolling mean for each town. Then slice out every fifth row.\n",
      "Your probably better off with OpenCV. Pixel value is not going to do much for you, you need to detect shapes. \n",
      "\n",
      "It’s been a long time since I’ve played with the image recognition but there are tutorials that take you through detecting faces or eyes. Should be similar.\n"
     ]
    }
   ],
   "source": [
    "submissions = reddit.subreddit('learnpython').hot(limit=10)\n",
    "for submission in submissions:\n",
    "    top_level_comments = list(submission.comments)\n",
    "    all_comments = submission.comments.list()[:2]\n",
    "    for comment in all_comments:\n",
    "        print(comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvYEOesKKcl2"
   },
   "source": [
    "Referring to the API documentation, explore the submissions object and print some interesting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glEShYZbKcl3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Khno5kpWKcl5"
   },
   "source": [
    "#### Posting to Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjnyN1OfKcl6"
   },
   "source": [
    "To be able to post to your Reddit account (i.e. contribute submissions), you need to connect to the API with read/write privilege. This requires an *authorised instance*, which is obtained by including your Reddit user name and password in the connection request: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXG7kouZKcl7"
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='my client id',\n",
    "                     client_secret='my client secret',\n",
    "                     user_agent='my user agent',\n",
    "                     username='my username',\n",
    "                     password='my password')\n",
    "print(reddit.read_only)  # Output: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEjrsF9vKcl-"
   },
   "source": [
    "You could hide these last two credentials by adding them to your JSON file and then reading all five values at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVcbR0K1Kcl_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqBG4xS5Kk3X"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EfPDz2gEKnRn"
   },
   "source": [
    ">\n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Uo-KnYhKoRA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> > > > > > > > > © 2019 Data Science Institute of Australia\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab 2.2.3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
