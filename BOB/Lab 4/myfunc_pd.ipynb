{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cenral Limit Theoram\n",
    "\n",
    "Simulated sampling (sample mean)\n",
    "\n",
    "Now, we'd like to get an idea of what happens when we take multiple random samples of size 5.\n",
    "\n",
    "Take 10 sample (size=5) from the entire population. Calculate means for each sample. Now make a histogram of all the sample means.\n",
    "\n",
    "Describe the shape of the histogram.\n",
    "What is the center of the distribution of sample means?\n",
    "\n",
    "'''\n",
    "def calculate_sample_mean(df, column_name, N=10, sample_size=5):\n",
    "    '''\n",
    "    df: DataFrame\n",
    "    column_name: String, column_name\n",
    "    N: Number of samples\n",
    "    sample_size: Size of sample for each sample\n",
    "    '''\n",
    "    sample_mean_list = []\n",
    "\n",
    "    for i in range(N):\n",
    "        df_sample = df.sample(n=sample_size)\n",
    "        sample_mean = df_sample[column_name].mean()\n",
    "        sample_mean_list.append(sample_mean)\n",
    "    \n",
    "    return sample_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visulize the sample mean and the dataset mean in the same histplot\n",
    "\n",
    "'''\n",
    "def visual_sample_mean(population_mean, sample_mean_list):\n",
    "    '''\n",
    "    population_mean: mean of entire population\n",
    "    sample_mean_list: list of sample mean\n",
    "    '''\n",
    "    \n",
    "    sample_mean = np.mean(sample_mean_list)\n",
    "    \n",
    "    ax = sns.distplot(sample_mean_list);\n",
    "    \n",
    "    # plot a vertical line for population mean and sample mean\n",
    "    ax.axvline(population_mean, color='black', linestyle='solid', lw=1)\n",
    "    ax.axvline(sample_mean, color='red', linestyle='dashed', lw=1)\n",
    "    \n",
    "    plt.xlabel('Mean of Samples')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning the author name\n",
    "\n",
    "calling funtion as df['Author'] = df['Author'].apply(clean_author_names)\n",
    "\n",
    "'''\n",
    "\n",
    "def clean_author_names(author):\n",
    "    \n",
    "    author = str(author)\n",
    "    \n",
    "    if author == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    author = author.split(',')\n",
    "\n",
    "    if len(author) == 1:\n",
    "        name = filter(lambda x: x.isalpha(), author[0])\n",
    "        return reduce(lambda x, y: x + y, name)\n",
    "    \n",
    "    last_name, first_name = author[0], author[1]\n",
    "\n",
    "    first_name = first_name[:first_name.find('-')] if '-' in first_name else first_name\n",
    "    \n",
    "    if first_name.endswith(('.', '.|')):\n",
    "        parts = first_name.split('.')\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            first_occurence = first_name.find('.')\n",
    "            final_occurence = first_name.find('.', first_occurence + 1)\n",
    "            first_name = first_name[:final_occurence]\n",
    "        else:\n",
    "            first_name = first_name[:first_name.find('.')]\n",
    "    \n",
    "    last_name = last_name.capitalize()\n",
    "    \n",
    "    return f'{first_name} {last_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Clean title for some title with by, By, []..\n",
    "\n",
    "calling funtion as \n",
    "\n",
    "df['Title'] = df['Title'].apply(clean_title)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def clean_title(title):\n",
    "    \n",
    "    if title == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    if title[0] == '[':\n",
    "        title = title[1: title.find(']')]\n",
    "        \n",
    "    if 'by' in title:\n",
    "        title = title[:title.find('by')]\n",
    "    elif 'By' in title:\n",
    "        title = title[:title.find('By')]\n",
    "        \n",
    "    if '[' in title:\n",
    "        title = title[:title.find('[')]\n",
    "\n",
    "    title = title[:-2]\n",
    "        \n",
    "    title = list(map(str.capitalize, title.split()))\n",
    "    return ' '.join(title)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datas cleaning \n",
    "\n",
    "df ---------- DataFrame\n",
    "col ---------- the name of column , as 'dates'\n",
    "\n",
    "calling funtion as \n",
    "\n",
    "df['Date of Publication'] = df.apply(clean_dates, axis = 1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def clean_dates(df, col):\n",
    "    \n",
    "    unwanted_characters = ['[', ',', '-']\n",
    "    \n",
    "    dop= str(df.loc[col])\n",
    "    \n",
    "    if dop == 'nan' or dop[0] == '[':\n",
    "        return np.NaN\n",
    "    \n",
    "    for character in unwanted_characters:\n",
    "        if character in dop:\n",
    "            character_index = dop.find(character)\n",
    "            dop = dop[:character_index]\n",
    "    \n",
    "    return dop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CUT Function ---  To make new category \n",
    "\n",
    "col ----------- column as df['AB']\n",
    "bins -----------  How many you want to cut as 2\n",
    "labels ----------  giving the list of labels as ['z','z']\n",
    "\n",
    "Calling as \n",
    "\n",
    "bikes['atemp_level'] = cut_add_new_category (bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "    \n",
    "\n",
    "** Set-up a new column to store\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def cut_add_new_category( col, N, labels ):\n",
    "    \n",
    "    atemp_level = pd.cut(col, bins = N, labels = labels)\n",
    "    \n",
    "    return atemp_level\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define the outlier for each column \n",
    "\n",
    "3 sigma boundary\n",
    "\n",
    "Calling as outlier_datapoints = detect_outlier(df['AAA'])\n",
    "'''\n",
    "\n",
    "def outlier_detect(data):\n",
    "   \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    outliers=[]\n",
    "    \n",
    "    \n",
    "    threshold=3\n",
    "    mean_1 = np.mean(data)\n",
    "    std_1 =np.std(data)\n",
    "    \n",
    "    \n",
    "    for y in data:\n",
    "        z_score= (y - mean_1)/std_1 \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers.append(y)\n",
    "    return outliers\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalize data process:\n",
    "\n",
    "Default value input is df['AAA']\n",
    "\n",
    "'''\n",
    "\n",
    "def NormData(s,low='min',center='mid',hi='max',insideout=False,shrinkfactor=0.):    \n",
    "    if low=='min':\n",
    "        low=min(s)\n",
    "    elif low=='abs':\n",
    "        low=max(abs(min(s)),abs(max(s)))*-1.#sign(min(s))\n",
    "    if hi=='max':\n",
    "        hi=max(s)\n",
    "    elif hi=='abs':\n",
    "        hi=max(abs(min(s)),abs(max(s)))*1.#sign(max(s))\n",
    "\n",
    "    if center=='mid':\n",
    "        center=(max(s)+min(s))/2\n",
    "    elif center=='avg':\n",
    "        center=np.mean(s)\n",
    "    elif center=='median':\n",
    "        center=np.median(s)\n",
    "\n",
    "    s2=[x-center for x in s]\n",
    "    hi=hi-center\n",
    "    low=low-center\n",
    "    center=0.\n",
    "\n",
    "    r=[]\n",
    "\n",
    "    for x in s2:\n",
    "        if x<low:\n",
    "            r.append(0.)\n",
    "        elif x>hi:\n",
    "            r.append(1.)\n",
    "        else:\n",
    "            if x>=center:\n",
    "                r.append((x-center)/(hi-center)*0.5+0.5)\n",
    "            else:\n",
    "                r.append((x-low)/(center-low)*0.5+0.)\n",
    "\n",
    "    if insideout==True:\n",
    "        ir=[(1.-abs(z-0.5)*2.) for z in r]\n",
    "        r=ir\n",
    "\n",
    "    rr =[x-(x-0.5)*shrinkfactor for x in r]    \n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To find the best features for linear regression:\n",
    "\n",
    "Need to set-up the dataframe name df....\n",
    "\n",
    "X-train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def linear_best_feature(df):\n",
    "   \n",
    "    ## Flag intermediate output\n",
    "\n",
    "    show_steps = False   # for testing/debugging\n",
    "    # show_steps = False  # without showing steps\n",
    "    \n",
    "    \n",
    "    ## Use Forward Feature Selection to pick a good model\n",
    "\n",
    "    # start with no predictors\n",
    "    included = []\n",
    "    # keep track of model and parameters\n",
    "    best = {'feature': '', 'r2': 0, 'a_r2': 0}\n",
    "    # create a model object to hold the modelling parameters\n",
    "    model = LinearRegression()\n",
    "    # get the number of cases in the test data\n",
    "    n = X_test.shape[0]\n",
    "    \n",
    "    r2_list = []\n",
    "    adjusted_r2_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        \n",
    "        changed = False\n",
    "    \n",
    "        if show_steps:\n",
    "            print('') \n",
    "\n",
    "        # list the features to be evaluated\n",
    "        excluded = list(set(df.columns) - set(included))\n",
    "        \n",
    "        if show_steps:\n",
    "            print('(Step) Excluded = %s' % ', '.join(excluded))  \n",
    "\n",
    "        # for each remaining feature to be evaluated\n",
    "        for new_column in excluded:\n",
    "            \n",
    "            if show_steps:\n",
    "                \n",
    "                print('(Step) Trying %s...' % new_column)\n",
    "                print('(Step) - Features = %s' % ', '.join(included + [new_column]))\n",
    "\n",
    "            # fit the model with the Training data\n",
    "            fit = model.fit(X_train[included + [new_column]], y_train)\n",
    "            # calculate the score (R^2 for Regression)\n",
    "            r2 = fit.score(X_train[included + [new_column]], y_train)\n",
    "        \n",
    "            # number of predictors in this model\n",
    "            k = len(included) + 1\n",
    "            # calculate the adjusted R^2\n",
    "            adjusted_r2 = 1 - ( ( (1 - r2) * (n - 1) ) / (n - k - 1) )\n",
    "        \n",
    "            if show_steps:\n",
    "                print('(Step) - Adjusted R^2: This = %.3f; Best = %.3f' % \n",
    "                      (adjusted_r2, best['a_r2']))\n",
    "\n",
    "            # if model improves\n",
    "            if adjusted_r2 > best['a_r2']:\n",
    "                # record new parameters\n",
    "                best = {'feature': new_column, 'r2': r2, 'a_r2': adjusted_r2}\n",
    "                # flag that found a better model\n",
    "                changed = True\n",
    "                if show_steps:\n",
    "                    print('(Step) - New Best!   : Feature = %s; R^2 = %.3f; Adjusted R^2 = %.3f' % \n",
    "                          (best['feature'], best['r2'], best['a_r2']))\n",
    "        # END for\n",
    "    \n",
    "        r2_list.append(best['r2'])\n",
    "        adjusted_r2_list.append(best['a_r2'])\n",
    "\n",
    "    # if found a better model after testing all remaining features\n",
    "        if changed:\n",
    "        # update control details\n",
    "            included.append(best['feature'])\n",
    "            excluded = list(set(excluded) - set(best['feature']))\n",
    "            print('Added feature %-4s with R^2 = %.3f and adjusted R^2 = %.3f' % \n",
    "                  (best['feature'], best['r2'], best['a_r2']))\n",
    "        else:\n",
    "            # terminate if no better model\n",
    "            print('*'*50)\n",
    "            break\n",
    "\n",
    "    print('')\n",
    "    print('Resulting features:')\n",
    "    print(', '.join(included))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
